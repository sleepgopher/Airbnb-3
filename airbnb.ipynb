{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Analysis of the Airbnb data of London\n",
    "\n",
    "In this project, we analyze the Airbnb data of London and try to use the data to predict the review scores of each listing. The data sets are available [here](http://insideairbnb.com/get-the-data.html).\n",
    "\n",
    "##Reading data\n",
    "\n",
    "There are three files, which are regarding the calendar, listings, and reviews. Among the three files, the listings data provide detailed information of the amenities, prices, description, etc. of all the listings. Thus, we focus on the listings data for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "listings = pd.read_csv('../Airbnb/src/data_sets/listings.csv.gz')\n",
    "listings = listings.rename(columns={'id': 'listing_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we want to predict the review scores, we remove all the missing values and bin it into five groups. Then we clean the data and transform the format of some of the variables that have (relatively) strong relationship with the review scores.\n",
    "\n",
    "Notice that special care has to be taken regarding the host verifications and amenities: Each item contains a list of features of each listing in a string format; thus, we first extract all the features in that string and then convert them into multiple variables of binary values where `1` indicates the presence of this feature and `0` indicates absence. Also, there are two amenities regarding missing translations; these are removed from the amenities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "resp = 'review_scores_rating'\n",
    "listings = listings[~listings[resp].isnull()].reset_index(0, True)\n",
    "listings[resp] = pd.cut(listings[resp], np.arange(0, 120, 20), labels=np.arange(5),\n",
    "                        include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_zipcode(df):\n",
    "    variable = 'zipcode'\n",
    "    df[variable] = df[variable].fillna('')\n",
    "    df[variable] = df[variable].str.upper().str.replace('[^0-9A-Z]+', '')\n",
    "    df.loc[df[variable].str.len() >= 8, variable] = ''\n",
    "    df.loc[df[variable].str.len() >= 5, variable] \\\n",
    "        = df.loc[df[variable].str.len() >= 5, variable].str.slice(0, -3)\n",
    "    return df\n",
    "\n",
    "\n",
    "listings = transform_zipcode(listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def transform_label(df, variables):\n",
    "    encoder = LabelEncoder()\n",
    "    for variable in variables:\n",
    "        df[variable] = df[variable].fillna('')\n",
    "        df[variable] = encoder.fit_transform(df[variable])\n",
    "    return df\n",
    "\n",
    "\n",
    "listings = transform_label(listings, ['experiences_offered',\n",
    "                                      'host_response_time',\n",
    "                                      'zipcode',\n",
    "                                      'property_type',\n",
    "                                      'room_type',\n",
    "                                      'bed_type',\n",
    "                                      'cancellation_policy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_host_since(df):\n",
    "    df['host_since'] = pd.to_datetime(df['host_since'], yearfirst=True)\n",
    "    df['host_for'] = (pd.Timestamp.now() - df['host_since']).dt.days\n",
    "    return df\n",
    "\n",
    "\n",
    "listings = transform_host_since(listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_boolean(df, variables):\n",
    "    for variable in variables:\n",
    "        df[variable] = df[variable].map({'f': 0, 't': 1}, 'ignore')\n",
    "    return df\n",
    "\n",
    "\n",
    "listings = transform_boolean(listings, ['host_is_superhost',\n",
    "                                        'host_has_profile_pic',\n",
    "                                        'host_identity_verified',\n",
    "                                        'is_location_exact',\n",
    "                                        'requires_license',\n",
    "                                        'instant_bookable',\n",
    "                                        'require_guest_profile_picture',\n",
    "                                        'require_guest_phone_verification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "def transform_text(df, variables):\n",
    "    vectorizer = CountVectorizer(stop_words='english', max_features=100)\n",
    "    tmp = []\n",
    "    for variable in variables:\n",
    "        df[variable] = df[variable].fillna('')\n",
    "        sparse = vectorizer.fit_transform(df[variable])\n",
    "        sparse = pd.DataFrame(sparse.toarray(), columns=sorted(vectorizer.vocabulary_.keys())) \\\n",
    "            .add_prefix(variable + '.')\n",
    "        tmp.append(sparse)\n",
    "    df = pd.DataFrame(pd.concat([df] + tmp, 1))\n",
    "    return df\n",
    "\n",
    "\n",
    "listings = transform_text(listings, ['host_verifications'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_percent(df, variables):\n",
    "    for variable in variables:\n",
    "        df[variable] = df[variable].str.strip('%')\n",
    "        df[variable] = df[variable].astype(np.float64) / 100\n",
    "    return df\n",
    "\n",
    "\n",
    "listings = transform_percent(listings, ['host_response_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_price(df, variables):\n",
    "    for variable in variables:\n",
    "        df[variable] = df[variable].str.strip('$').str.replace(',', '')\n",
    "        df[variable] = df[variable].astype(np.float64)\n",
    "    return df\n",
    "\n",
    "\n",
    "listings = transform_price(listings, ['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_amenities(df):\n",
    "    variable = 'amenities'\n",
    "    df[variable] = df[variable].str.replace(r'[:\\-\\./ ]', '_').str.replace(r'[\\(\\)]', '') \\\n",
    "        .str.replace(r'_+', '_').str.lower()\n",
    "    df = transform_text(df, [variable])\n",
    "    columns_to_remove = [column for column in df.columns if 'missing' in column]\n",
    "    df = pd.DataFrame(df.drop(columns_to_remove, 1))\n",
    "    return df\n",
    "\n",
    "\n",
    "listings = transform_amenities(listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transforming the format of the variables, we remove those that have high percentage of missing values and/or have little or no relationship with the review scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = listings.drop(['listing_url',\n",
    "                          'scrape_id',\n",
    "                          'last_scraped',\n",
    "                          'name',\n",
    "                          'summary',\n",
    "                          'space',\n",
    "                          'description',\n",
    "                          'neighborhood_overview',\n",
    "                          'notes',\n",
    "                          'transit',\n",
    "                          'access',\n",
    "                          'interaction',\n",
    "                          'house_rules',\n",
    "                          'thumbnail_url',\n",
    "                          'medium_url',\n",
    "                          'picture_url',\n",
    "                          'xl_picture_url',\n",
    "                          'host_url',\n",
    "                          'host_name',\n",
    "                          'host_since',\n",
    "                          'host_location',\n",
    "                          'host_about',\n",
    "                          'host_acceptance_rate',\n",
    "                          'host_thumbnail_url',\n",
    "                          'host_picture_url',\n",
    "                          'host_neighbourhood',\n",
    "                          'host_listings_count',\n",
    "                          'host_total_listings_count',\n",
    "                          'host_verifications',\n",
    "                          'host_has_profile_pic',\n",
    "                          'host_identity_verified',\n",
    "                          'street',\n",
    "                          'neighbourhood',\n",
    "                          'neighbourhood_cleansed',\n",
    "                          'neighbourhood_group_cleansed',\n",
    "                          'city',\n",
    "                          'state',\n",
    "                          'market',\n",
    "                          'smart_location',\n",
    "                          'country_code',\n",
    "                          'country',\n",
    "                          'latitude',\n",
    "                          'longitude',\n",
    "                          'is_location_exact',\n",
    "                          'amenities',\n",
    "                          'square_feet',\n",
    "                          'weekly_price',\n",
    "                          'monthly_price',\n",
    "                          'security_deposit',\n",
    "                          'cleaning_fee',\n",
    "                          'guests_included',\n",
    "                          'extra_people',\n",
    "                          'minimum_nights',\n",
    "                          'maximum_nights',\n",
    "                          'calendar_updated',\n",
    "                          'has_availability',\n",
    "                          'availability_30',\n",
    "                          'availability_60',\n",
    "                          'availability_90',\n",
    "                          'availability_365',\n",
    "                          'calendar_last_scraped',\n",
    "                          'first_review',\n",
    "                          'last_review',\n",
    "                          'review_scores_accuracy',\n",
    "                          'review_scores_cleanliness',\n",
    "                          'review_scores_checkin',\n",
    "                          'review_scores_communication',\n",
    "                          'review_scores_location',\n",
    "                          'review_scores_value',\n",
    "                          'requires_license',\n",
    "                          'license',\n",
    "                          'jurisdiction_names',\n",
    "                          'instant_bookable',\n",
    "                          'cancellation_policy',\n",
    "                          'require_guest_profile_picture',\n",
    "                          'require_guest_phone_verification',\n",
    "                          'reviews_per_month'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are too many variables regarding host verifications and amenities, and some of them may be redundant to predict the review scores. For example, almost every host is verified by phone, so this variable is of little significance. Therefore, we perform $\\chi^{2}$ test to contract the feature space by selecting those with a significantly small $p$-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "def remove_redundant_features(df, variables):\n",
    "    for variable in variables:\n",
    "        variables_list = [item for item in listings.columns if variable in item]\n",
    "        tmp = df[variables_list + [resp]].dropna()\n",
    "        _, p_val = chi2(tmp[variables_list], tmp[resp])\n",
    "        variables_list = list(compress(variables_list, (p_val > 0.05)))\n",
    "        df = df.drop(variables_list, 1)\n",
    "    return df\n",
    "\n",
    "\n",
    "listings = remove_redundant_features(listings, ['host_verifications', 'amenities'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the redundant variables, the split the data into the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train, test = train_test_split(listings)\n",
    "train = train.reset_index(0, True)\n",
    "test = test.reset_index(0, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are two variables of high cardinality, which are the host ID and zipcode. We transform them by blending the prior and the posterior of each class of the variables using an S-shape function parameterized by the number of samples in that class: when we have more samples in that class, we tend to trust more on the posterior; if we have few samples, we tend to use the prior more as the posterior estimate would be highly unreliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "F = 5\n",
    "R = 0.01\n",
    "\n",
    "\n",
    "def compute_lambda(count):\n",
    "    return 1 / (1 + np.exp(-(count - K) / F))\n",
    "\n",
    "\n",
    "def compute_prob(row):\n",
    "    prior, posterior, lambda_val = row\n",
    "    return lambda_val * posterior + (1 - lambda_val) * prior\n",
    "\n",
    "\n",
    "def transform_train_test(train, test, variables):\n",
    "    prior = train[resp].value_counts(True).sort_index().reset_index()\n",
    "    prior['index'] = prior['index'].map(lambda x: 'prior.' + str(x))\n",
    "    prior = prior.transpose()\n",
    "    prior = prior.rename(columns=prior.iloc[0]).drop('index', 0).reset_index()\n",
    "    \n",
    "    for variable in variables:\n",
    "        new_prior = pd.DataFrame(pd.concat([prior] * len(train[variable].unique()),\n",
    "                                           ignore_index=True))\n",
    "        new_prior['index'] = train[variable].unique()\n",
    "        new_prior = new_prior.rename(columns={'index': variable})\n",
    "\n",
    "        posterior = train.groupby(variable)[resp].value_counts(True) \\\n",
    "            .rename(variable + '.posterior').reset_index()\n",
    "        posterior = posterior.pivot(index=variable,\n",
    "                                    columns=resp,\n",
    "                                    values=variable + '.posterior').reset_index().fillna(0)\n",
    "        columns = dict(zip(np.arange(5),\n",
    "                           [variable + '.posterior.' + score\n",
    "                            for score in np.arange(5).astype(str)]))\n",
    "        posterior = posterior.rename(columns=columns)\n",
    "\n",
    "        count = train.groupby([variable, resp])[resp].count() \\\n",
    "            .rename(variable + '.count').reset_index()\n",
    "        count[resp] = count[resp].astype(np.int64)\n",
    "        count = count.pivot(index=variable,\n",
    "                            columns=resp,\n",
    "                            values=variable + '.count').reset_index().fillna(0)\n",
    "        columns = dict(zip(np.arange(5),\n",
    "                           [variable + '.count.' + score\n",
    "                            for score in np.arange(5).astype(str)]))\n",
    "        count = count.rename(columns=columns)\n",
    "        \n",
    "        tmp = new_prior.merge(posterior).merge(count)\n",
    "        \n",
    "        for i in np.arange(5):\n",
    "            tmp[variable + '.lambda.' + str(i)] = tmp[variable + '.count.' + str(i)] \\\n",
    "                .map(compute_lambda)\n",
    "        \n",
    "        for i in np.arange(5):\n",
    "            tmp[variable + '.prob.' + str(i)] = tmp[['prior.' + str(i),\n",
    "                                                     variable + '.posterior.' + str(i),\n",
    "                                                     variable + '.lambda.' + str(i)]] \\\n",
    "                .apply(compute_prob, 1)\n",
    "        \n",
    "        tmp = tmp[[variable] + [variable + '.prob.' + str(i) for i in np.arange(5)]]\n",
    "        train = train.merge(tmp, 'left').drop(variable, 1)\n",
    "        train[[variable + '.prob.' + str(i) for i in np.arange(5)]] \\\n",
    "            *= (1 + np.random.uniform(-0.5, 0.5, (len(train), 5)) * R)\n",
    "        test = test.merge(tmp, 'left').drop(variable, 1)\n",
    "        test[[variable + '.prob.' + str(i) for i in np.arange(5)]] \\\n",
    "            *= (1 + np.random.uniform(-0.5, 0.5, (len(test), 5)) * R)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = transform_train_test(train, test, ['host_id', 'zipcode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the transformed data to train an XGBoost classifier to predict the review scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop([resp, 'listing_id'], 1)\n",
    "y_train = train[resp]\n",
    "X_test = test.drop([resp, 'listing_id'], 1)\n",
    "y_test = test[resp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "d_train = xgb.DMatrix(X_train, y_train)\n",
    "\n",
    "params = {'silent': 1,\n",
    "          'eta': 0.05,\n",
    "          'max_depth': 5,\n",
    "          'subsample': 0.75,\n",
    "          'colsample_bytree': 0.75,\n",
    "          'objective': 'multi:softmax',\n",
    "          'num_class': 5,\n",
    "          'eval_metric': 'mlogloss'}\n",
    "num_boost_round = 1000\n",
    "\n",
    "bst = xgb.train(params, d_train, num_boost_round)\n",
    "\n",
    "d_test = xgb.DMatrix(X_test)\n",
    "pred = bst.predict(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}